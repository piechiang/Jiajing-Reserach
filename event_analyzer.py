# -*- coding: utf-8 -*-
"""
äº‹ä»¶åˆ†æå·¥å…· - æ·±å…¥åˆ†æå¤§ç¤¼è®®å…³é”®äº‹ä»¶
"""
import sys
import re
from pathlib import Path

if hasattr(sys.stdout, 'reconfigure'):
    sys.stdout.reconfigure(encoding='utf-8')
if hasattr(sys.stderr, 'reconfigure'):
    sys.stderr.reconfigure(encoding='utf-8')


class EventAnalyzer:
    """äº‹ä»¶åˆ†æå™¨"""

    def __init__(self, data_file):
        self.data_file = Path(data_file)
        self.content = ""
        self.load_data()

    def load_data(self):
        """åŠ è½½æ•°æ®"""
        if not self.data_file.exists():
            print(f"é”™è¯¯: æ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶ {self.data_file}")
            return False

        with open(self.data_file, 'r', encoding='utf-8') as f:
            self.content = f.read()

        print(f"âœ“ å·²åŠ è½½æ•°æ®: {len(self.content):,}å­—")
        return True

    def find_event_contexts(self, keyword, context_length=300):
        """
        æŸ¥æ‰¾äº‹ä»¶å…³é”®è¯çš„æ‰€æœ‰å‡ºç°ä½ç½®åŠä¸Šä¸‹æ–‡

        Args:
            keyword: å…³é”®è¯
            context_length: ä¸Šä¸‹æ–‡å­—ç¬¦æ•°

        Returns:
            list: ä¸Šä¸‹æ–‡åˆ—è¡¨
        """
        contexts = []
        pos = 0

        while True:
            pos = self.content.find(keyword, pos)
            if pos == -1:
                break

            # æå–ä¸Šä¸‹æ–‡
            start = max(0, pos - context_length)
            end = min(len(self.content), pos + len(keyword) + context_length)

            context = self.content[start:end]

            # å°è¯•æå–æ—¥æœŸä¿¡æ¯
            date_match = re.search(r'(å˜‰é–\w+å¹´\w+æœˆ\w+æ—¥?)', context)
            date = date_match.group(1) if date_match else "æœªçŸ¥æ—¥æœŸ"

            contexts.append({
                'position': pos,
                'date': date,
                'before': self.content[start:pos],
                'keyword': keyword,
                'after': self.content[pos + len(keyword):end],
                'full_context': context
            })

            pos += len(keyword)

        return contexts

    def analyze_event(self, event_name, keywords):
        """
        åˆ†æç‰¹å®šäº‹ä»¶

        Args:
            event_name: äº‹ä»¶åç§°
            keywords: å…³é”®è¯åˆ—è¡¨
        """
        print("\n" + "=" * 60)
        print(f"äº‹ä»¶åˆ†æ: {event_name}")
        print("=" * 60)

        all_contexts = []

        # æœç´¢æ‰€æœ‰å…³é”®è¯
        for keyword in keywords:
            contexts = self.find_event_contexts(keyword, context_length=400)
            if contexts:
                print(f"\nğŸ“Œ å…³é”®è¯ '{keyword}' å‡ºç° {len(contexts)} æ¬¡")
                all_contexts.extend(contexts)

        if not all_contexts:
            print(f"\nâŒ æœªæ‰¾åˆ°ä¸ '{event_name}' ç›¸å…³çš„å†…å®¹")
            return

        # æŒ‰ä½ç½®æ’åº
        all_contexts.sort(key=lambda x: x['position'])

        # æ˜¾ç¤ºæ‰€æœ‰ç›¸å…³æ®µè½
        print(f"\nğŸ“– ç›¸å…³æ®µè½ (å…±{len(all_contexts)}å¤„):\n")

        for i, ctx in enumerate(all_contexts, 1):
            print(f"\n[{i}] {ctx['date']}")
            print("-" * 60)
            # é«˜äº®å…³é”®è¯
            text = ctx['full_context']
            for kw in keywords:
                text = text.replace(kw, f"ã€{kw}ã€‘")
            print(text)
            print("-" * 60)

        # ä¿å­˜åˆ°æ–‡ä»¶
        output_file = Path(f"analysis_{event_name}.txt")
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(f"äº‹ä»¶åˆ†ææŠ¥å‘Š: {event_name}\n")
            f.write("=" * 60 + "\n\n")

            for i, ctx in enumerate(all_contexts, 1):
                f.write(f"\n[{i}] {ctx['date']}\n")
                f.write("-" * 60 + "\n")
                f.write(ctx['full_context'] + "\n")
                f.write("-" * 60 + "\n")

        print(f"\nâœ“ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {output_file}")

    def analyze_person_in_event(self, person_name, event_keywords):
        """
        åˆ†æç‰¹å®šäººç‰©åœ¨äº‹ä»¶ä¸­çš„è¡¨ç°

        Args:
            person_name: äººç‰©åå­—
            event_keywords: äº‹ä»¶å…³é”®è¯åˆ—è¡¨
        """
        print("\n" + "=" * 60)
        print(f"äººç‰©åœ¨äº‹ä»¶ä¸­çš„è¡¨ç°: {person_name}")
        print("=" * 60)

        # æ‰¾åˆ°åŒ…å«äººç‰©å’Œäº‹ä»¶å…³é”®è¯çš„æ®µè½
        relevant_contexts = []

        for keyword in event_keywords:
            contexts = self.find_event_contexts(keyword, context_length=500)

            for ctx in contexts:
                if person_name in ctx['full_context']:
                    relevant_contexts.append({
                        'event_keyword': keyword,
                        'context': ctx
                    })

        if not relevant_contexts:
            print(f"\nâŒ æœªæ‰¾åˆ° '{person_name}' åœ¨ç›¸å…³äº‹ä»¶ä¸­çš„è®°å½•")
            return

        print(f"\næ‰¾åˆ° {len(relevant_contexts)} å¤„ç›¸å…³è®°å½•:\n")

        for i, item in enumerate(relevant_contexts, 1):
            ctx = item['context']
            print(f"\n[{i}] äº‹ä»¶: {item['event_keyword']} | æ—¥æœŸ: {ctx['date']}")
            print("-" * 60)

            # é«˜äº®äººç‰©åå­—å’Œäº‹ä»¶å…³é”®è¯
            text = ctx['full_context']
            text = text.replace(person_name, f"ã€{person_name}ã€‘")
            text = text.replace(item['event_keyword'], f"ã€{item['event_keyword']}ã€")
            print(text)
            print("-" * 60)

        # ä¿å­˜æŠ¥å‘Š
        output_file = Path(f"analysis_{person_name}_in_events.txt")
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(f"äººç‰©åœ¨äº‹ä»¶ä¸­çš„è¡¨ç°: {person_name}\n")
            f.write("=" * 60 + "\n\n")

            for i, item in enumerate(relevant_contexts, 1):
                ctx = item['context']
                f.write(f"\n[{i}] äº‹ä»¶: {item['event_keyword']} | æ—¥æœŸ: {ctx['date']}\n")
                f.write("-" * 60 + "\n")
                f.write(ctx['full_context'] + "\n")
                f.write("-" * 60 + "\n")

        print(f"\nâœ“ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {output_file}")

    def timeline_analysis(self, keywords):
        """
        æ—¶é—´çº¿åˆ†æ - è¿½è¸ªäº‹ä»¶çš„å‘å±•è¿‡ç¨‹

        Args:
            keywords: ç›¸å…³å…³é”®è¯åˆ—è¡¨
        """
        print("\n" + "=" * 60)
        print("æ—¶é—´çº¿åˆ†æ")
        print("=" * 60)

        all_events = []

        for keyword in keywords:
            contexts = self.find_event_contexts(keyword, context_length=200)

            for ctx in contexts:
                # æå–æ›´è¯¦ç»†çš„æ—¥æœŸ
                date_match = re.search(r'å˜‰é–(\w+)å¹´(\w+æœˆ)?(\w+æ—¥)?', ctx['full_context'])

                if date_match:
                    year = date_match.group(1)
                    month = date_match.group(2) if date_match.group(2) else ""
                    day = date_match.group(3) if date_match.group(3) else ""
                    full_date = f"å˜‰é–{year}{month}{day}"
                else:
                    full_date = "æ—¥æœŸä¸æ˜"

                all_events.append({
                    'date': full_date,
                    'keyword': keyword,
                    'context': ctx['full_context'][:200]
                })

        if not all_events:
            print("\nâŒ æœªæ‰¾åˆ°ç›¸å…³äº‹ä»¶")
            return

        # æŒ‰æ—¥æœŸåˆ†ç»„
        print(f"\nğŸ“… å…±æ‰¾åˆ° {len(all_events)} ä¸ªäº‹ä»¶è®°å½•\n")

        date_groups = {}
        for event in all_events:
            date = event['date']
            if date not in date_groups:
                date_groups[date] = []
            date_groups[date].append(event)

        # æ˜¾ç¤ºæ—¶é—´çº¿
        for date in sorted(date_groups.keys()):
            events = date_groups[date]
            print(f"\nã€{date}ã€‘")
            for event in events:
                print(f"  â€¢ {event['keyword']}: {event['context'][:100]}...")

        print("\n" + "=" * 60)


def main():
    """ä¸»ç¨‹åº"""
    print("=" * 60)
    print("å¤§ç¤¼è®®äº‹ä»¶åˆ†æå·¥å…·")
    print("=" * 60)

    # åŠ è½½æ•°æ®
    data_file = "jiajing_data_from_pdf/complete_vol1-45.txt"
    analyzer = EventAnalyzer(data_file)

    print("\né€‰æ‹©åˆ†æç±»å‹:")
    print("1. å·¦é¡ºé—¨äº‹ä»¶åˆ†æ")
    print("2. å»·æ–äº‹ä»¶åˆ†æ")
    print("3. å¤§ç¤¼è®®æ•´ä½“åˆ†æ")
    print("4. åˆ†æç‰¹å®šäººç‰©åœ¨äº‹ä»¶ä¸­çš„è¡¨ç°")
    print("5. è‡ªå®šä¹‰äº‹ä»¶åˆ†æ")
    print("=" * 60)

    choice = input("\nè¯·é€‰æ‹© (1-5): ").strip()

    if choice == "1":
        # å·¦é¡ºé—¨äº‹ä»¶
        analyzer.analyze_event(
            "å·¦é¡ºé—¨äº‹ä»¶",
            ["å·¦é¡ºé—¨", "ä¼å“­", "æ’¼é—¨", "å“­è°"]
        )

    elif choice == "2":
        # å»·æ–äº‹ä»¶
        analyzer.analyze_event(
            "å»·æ–äº‹ä»¶",
            ["å»·æ–", "æ–", "è´£", "ä¸‹ç‹±"]
        )

    elif choice == "3":
        # å¤§ç¤¼è®®æ•´ä½“
        analyzer.analyze_event(
            "å¤§ç¤¼è®®",
            ["å¤§ç¤¼", "è®®ç¤¼", "ç§°å®—", "çŒ®çš‡å¸", "å…´çŒ®ç‹", "çš‡è€ƒ"]
        )

    elif choice == "4":
        # äººç‰©åœ¨äº‹ä»¶ä¸­çš„è¡¨ç°
        person = input("\nè¯·è¾“å…¥äººç‰©åå­— (å¦‚: æ¨å»·å’Œ, å¼ ç’, æ¯›æ¾„): ").strip()
        print("\né€‰æ‹©äº‹ä»¶ç±»å‹:")
        print("1. å·¦é¡ºé—¨äº‹ä»¶")
        print("2. å»·æ–äº‹ä»¶")
        print("3. å¤§ç¤¼è®®")

        event_choice = input("é€‰æ‹© (1-3): ").strip()

        if event_choice == "1":
            keywords = ["å·¦é¡ºé—¨", "ä¼å“­", "æ’¼é—¨"]
        elif event_choice == "2":
            keywords = ["å»·æ–", "æ–è´£", "ä¸‹ç‹±"]
        else:
            keywords = ["å¤§ç¤¼", "è®®ç¤¼", "ç§°å®—"]

        analyzer.analyze_person_in_event(person, keywords)

    elif choice == "5":
        # è‡ªå®šä¹‰
        keywords_input = input("\nè¯·è¾“å…¥å…³é”®è¯ (ç”¨é€—å·åˆ†éš”): ").strip()
        keywords = [k.strip() for k in keywords_input.split(',')]
        event_name = input("è¯·è¾“å…¥äº‹ä»¶åç§°: ").strip()

        analyzer.analyze_event(event_name, keywords)

    else:
        print("âŒ æ— æ•ˆé€‰æ‹©")

    print("\n" + "=" * 60)
    print("åˆ†æå®Œæˆ!")
    print("=" * 60)


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\næ“ä½œè¢«ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
